{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "third-cigarette",
   "metadata": {},
   "source": [
    "# GCN practice code\n",
    "\n",
    "- import basic library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "existing-dancing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import from_networkx\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from random import randint, expovariate\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dried-spare",
   "metadata": {},
   "source": [
    "- Generate the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "possible-oasis",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_CPU_MAX = []\n",
    "S_BW_MAX = []\n",
    "net = nx.gnm_random_graph(n=20, m=100)\n",
    "\n",
    "min_cpu_capacity = 1.0e10\n",
    "max_cpu_capacity = 0.0\n",
    "for node_id in net.nodes:\n",
    "    net.nodes[node_id]['CPU'] = randint(50, 100)\n",
    "    net.nodes[node_id]['LOCATION'] = randint(0, 2)\n",
    "    if net.nodes[node_id]['CPU'] < min_cpu_capacity:\n",
    "        min_cpu_capacity = net.nodes[node_id]['CPU']\n",
    "    if net.nodes[node_id]['CPU'] > max_cpu_capacity:\n",
    "        max_cpu_capacity = net.nodes[node_id]['CPU']\n",
    "        \n",
    "min_bandwidth_capacity = 1.0e10\n",
    "max_bandwidth_capacity = 0.0\n",
    "for edge_id in net.edges:\n",
    "    net.edges[edge_id]['bandwidth'] = randint(50, 100)\n",
    "    if net.edges[edge_id]['bandwidth'] < min_bandwidth_capacity:\n",
    "        min_bandwidth_capacity = net.edges[edge_id]['bandwidth']\n",
    "    if net.edges[edge_id]['bandwidth'] > max_bandwidth_capacity:\n",
    "        max_bandwidth_capacity = net.edges[edge_id]['bandwidth']\n",
    "        \n",
    "for s_node_id, s_node_data in net.nodes(data=True):\n",
    "    S_CPU_MAX.append(s_node_data['CPU'])\n",
    "# S_BW_Free\n",
    "for s_node_id in range(len(net.nodes)):\n",
    "    total_node_bandwidth = 0.0\n",
    "    for link_id in net[s_node_id]:\n",
    "        total_node_bandwidth += net[s_node_id][link_id]['bandwidth']\n",
    "    S_BW_MAX.append(total_node_bandwidth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "promotional-branch",
   "metadata": {},
   "outputs": [],
   "source": [
    " # S_CPU_Free\n",
    "s_CPU_remaining = []\n",
    "s_bandwidth_remaining = []\n",
    "current_embedding = [0] * len(net.nodes)\n",
    "\n",
    "for s_node_id, s_node_data in net.nodes(data=True):\n",
    "    s_CPU_remaining.append(s_node_data['CPU'])\n",
    "# S_BW_Free\n",
    "for s_node_id in range(len(net.nodes)):\n",
    "    total_node_bandwidth = 0.0\n",
    "    for link_id in net[s_node_id]:\n",
    "        total_node_bandwidth += net[s_node_id][link_id]['bandwidth']\n",
    "    s_bandwidth_remaining.append(total_node_bandwidth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "speaking-polyester",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[72, 96, 88, 89, 90, 70, 79, 78, 78, 93, 77, 54, 63, 63, 75, 100, 86, 78, 72, 56], [346.0, 771.0, 702.0, 469.0, 1084.0, 660.0, 804.0, 462.0, 759.0, 1065.0, 865.0, 344.0, 691.0, 967.0, 1262.0, 756.0, 864.0, 767.0, 871.0, 811.0], [72, 96, 88, 89, 90, 70, 79, 78, 78, 93, 77, 54, 63, 63, 75, 100, 86, 78, 72, 56], [346.0, 771.0, 702.0, 469.0, 1084.0, 660.0, 804.0, 462.0, 759.0, 1065.0, 865.0, 344.0, 691.0, 967.0, 1262.0, 756.0, 864.0, 767.0, 871.0, 811.0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "substrate_features = []\n",
    "substrate_features.append(S_CPU_MAX)\n",
    "substrate_features.append(S_BW_MAX)\n",
    "substrate_features.append(s_CPU_remaining)\n",
    "substrate_features.append(s_bandwidth_remaining)\n",
    "substrate_features.append(current_embedding)\n",
    "\n",
    "print(substrate_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "voluntary-favorite",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  72.,   96.,   88.,   89.,   90.,   70.,   79.,   78.,   78.,   93.,\n",
      "           77.,   54.,   63.,   63.,   75.,  100.,   86.,   78.,   72.,   56.],\n",
      "        [ 346.,  771.,  702.,  469., 1084.,  660.,  804.,  462.,  759., 1065.,\n",
      "          865.,  344.,  691.,  967., 1262.,  756.,  864.,  767.,  871.,  811.],\n",
      "        [  72.,   96.,   88.,   89.,   90.,   70.,   79.,   78.,   78.,   93.,\n",
      "           77.,   54.,   63.,   63.,   75.,  100.,   86.,   78.,   72.,   56.],\n",
      "        [ 346.,  771.,  702.,  469., 1084.,  660.,  804.,  462.,  759., 1065.,\n",
      "          865.,  344.,  691.,  967., 1262.,  756.,  864.,  767.,  871.,  811.],\n",
      "        [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
      "            0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.]])\n",
      "torch.Size([5, 20])\n",
      "tensor([[  72.,  346.,   72.,  346.,    0.],\n",
      "        [  96.,  771.,   96.,  771.,    0.],\n",
      "        [  88.,  702.,   88.,  702.,    0.],\n",
      "        [  89.,  469.,   89.,  469.,    0.],\n",
      "        [  90., 1084.,   90., 1084.,    0.],\n",
      "        [  70.,  660.,   70.,  660.,    0.],\n",
      "        [  79.,  804.,   79.,  804.,    0.],\n",
      "        [  78.,  462.,   78.,  462.,    0.],\n",
      "        [  78.,  759.,   78.,  759.,    0.],\n",
      "        [  93., 1065.,   93., 1065.,    0.],\n",
      "        [  77.,  865.,   77.,  865.,    0.],\n",
      "        [  54.,  344.,   54.,  344.,    0.],\n",
      "        [  63.,  691.,   63.,  691.,    0.],\n",
      "        [  63.,  967.,   63.,  967.,    0.],\n",
      "        [  75., 1262.,   75., 1262.,    0.],\n",
      "        [ 100.,  756.,  100.,  756.,    0.],\n",
      "        [  86.,  864.,   86.,  864.,    0.],\n",
      "        [  78.,  767.,   78.,  767.,    0.],\n",
      "        [  72.,  871.,   72.,  871.,    0.],\n",
      "        [  56.,  811.,   56.,  811.,    0.]])\n",
      "torch.Size([20, 5])\n"
     ]
    }
   ],
   "source": [
    "substrate_features = torch.tensor(substrate_features)\n",
    "print(substrate_features)\n",
    "print(substrate_features.shape)\n",
    "substrate_features = torch.transpose(substrate_features, 0, 1)\n",
    "print(substrate_features)\n",
    "print(substrate_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "streaming-overview",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100])\n",
      "tensor([ 74., 799.,  74., 799.,   0.,  88., 752.,  88., 752.,   0.,  98., 604.,\n",
      "         98., 604.,   0.,  51., 622.,  51., 622.,   0.,  80., 930.,  80., 930.,\n",
      "          0.,  50., 989.,  50., 989.,   0.,  74., 771.,  74., 771.,   0.,  63.,\n",
      "        431.,  63., 431.,   0.,  64., 970.,  64., 970.,   0.,  99., 867.,  99.,\n",
      "        867.,   0.,  91., 575.,  91., 575.,   0.,  83., 688.,  83., 688.,   0.,\n",
      "         92., 831.,  92., 831.,   0.,  86., 801.,  86., 801.,   0.,  64., 894.,\n",
      "         64., 894.,   0.,  96., 526.,  96., 526.,   0.,  74., 600.,  74., 600.,\n",
      "          0.,  99., 942.,  99., 942.,   0.,  88., 529.,  88., 529.,   0., 100.,\n",
      "        629., 100., 629.,   0.])\n"
     ]
    }
   ],
   "source": [
    "substrate_features = torch.reshape(substrate_features, (-1,))\n",
    "print(substrate_features.shape)\n",
    "print(substrate_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "sweet-bangkok",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vnr_cpu = torch.tensor([10])\n",
    "# vnr_bw = torch.tensor([30])\n",
    "# pending = torch.tensor([2])\n",
    "# substrate_features = torch.cat((substrate_features, vnr_cpu, vnr_bw, pending), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "considered-literacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(substrate_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unauthorized-brick",
   "metadata": {},
   "source": [
    "- Using 'from_networkx'\n",
    "    - transfer the torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "capital-blanket",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = from_networkx(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "needed-repository",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(CPU=[20], LOCATION=[20], bandwidth=[200], edge_index=[2, 200])\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forbidden-relief",
   "metadata": {},
   "source": [
    "### Graph Convolution Network\n",
    "- Generate the GCN class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "better-awareness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (conv1): GCNConv(5, 4)\n",
      "  (conv2): GCNConv(4, 4)\n",
      "  (conv3): GCNConv(4, 1)\n",
      "  (classifier): Linear(in_features=1, out_features=20, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import Linear\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = GCNConv(in_channels=5, out_channels=4)\n",
    "        self.conv2 = GCNConv(in_channels=4, out_channels=4)\n",
    "        self.conv3 = GCNConv(in_channels=4, out_channels=1)\n",
    "        self.classifier = Linear(1, 20)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        h = self.conv1(x, edge_index)\n",
    "        h = h.tanh()\n",
    "        h = self.conv2(h, edge_index)\n",
    "        h = h.tanh()\n",
    "        h = self.conv3(h, edge_index)\n",
    "        h = h.tanh()  # Final GNN embedding space.\n",
    "        \n",
    "        # Apply a final (linear) classifier.\n",
    "        out = self.classifier(h)\n",
    "\n",
    "        return out, h\n",
    "\n",
    "model = GCN()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "liberal-student",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 5]) torch.Size([2, 200])\n",
      "tensor([[  72.,  346.,   72.,  346.,    0.],\n",
      "        [  96.,  771.,   96.,  771.,    0.],\n",
      "        [  88.,  702.,   88.,  702.,    0.],\n",
      "        [  89.,  469.,   89.,  469.,    0.],\n",
      "        [  90., 1084.,   90., 1084.,    0.],\n",
      "        [  70.,  660.,   70.,  660.,    0.],\n",
      "        [  79.,  804.,   79.,  804.,    0.],\n",
      "        [  78.,  462.,   78.,  462.,    0.],\n",
      "        [  78.,  759.,   78.,  759.,    0.],\n",
      "        [  93., 1065.,   93., 1065.,    0.],\n",
      "        [  77.,  865.,   77.,  865.,    0.],\n",
      "        [  54.,  344.,   54.,  344.,    0.],\n",
      "        [  63.,  691.,   63.,  691.,    0.],\n",
      "        [  63.,  967.,   63.,  967.,    0.],\n",
      "        [  75., 1262.,   75., 1262.,    0.],\n",
      "        [ 100.,  756.,  100.,  756.,    0.],\n",
      "        [  86.,  864.,   86.,  864.,    0.],\n",
      "        [  78.,  767.,   78.,  767.,    0.],\n",
      "        [  72.,  871.,   72.,  871.,    0.],\n",
      "        [  56.,  811.,   56.,  811.,    0.]])\n",
      "Embedding shape: [20, 1]\n"
     ]
    }
   ],
   "source": [
    "model = GCN()\n",
    "\n",
    "print(substrate_features.shape, data.edge_index.shape)\n",
    "print(substrate_features)\n",
    "\n",
    "out, embedding = model(substrate_features, data.edge_index)\n",
    "print(f'Embedding shape: {list(embedding.shape)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "indoor-republic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8147],\n",
      "        [0.9048],\n",
      "        [0.8893],\n",
      "        [0.8435],\n",
      "        [0.9488],\n",
      "        [0.8798],\n",
      "        [0.9104],\n",
      "        [0.8439],\n",
      "        [0.9060],\n",
      "        [0.9504],\n",
      "        [0.9157],\n",
      "        [0.8028],\n",
      "        [0.9105],\n",
      "        [0.9169],\n",
      "        [0.9504],\n",
      "        [0.9105],\n",
      "        [0.9205],\n",
      "        [0.9106],\n",
      "        [0.9319],\n",
      "        [0.9183]], grad_fn=<TanhBackward>)\n",
      "torch.Size([20, 1])\n"
     ]
    }
   ],
   "source": [
    "print(embedding)\n",
    "print(embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "expressed-ottawa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 20])\n",
      "tensor([[ 0.3816, -1.2462,  0.5695,  0.1170, -0.6605, -0.7185, -0.7190,  0.6389,\n",
      "          0.7770, -0.1771,  0.1242,  0.4228,  0.0096, -0.2680,  0.1743, -0.2620,\n",
      "         -1.3410, -0.1200,  0.2875, -0.1379],\n",
      "        [ 0.4609, -1.3267,  0.6344,  0.2160, -0.6658, -0.7883, -0.7665,  0.7383,\n",
      "          0.8392, -0.1539,  0.1131,  0.4253,  0.0094, -0.2943,  0.1922, -0.3628,\n",
      "         -1.4549, -0.1028,  0.2432, -0.1585],\n",
      "        [ 0.3823, -1.2470,  0.5702,  0.1180, -0.6605, -0.7192, -0.7194,  0.6399,\n",
      "          0.7776, -0.1769,  0.1240,  0.4228,  0.0096, -0.2683,  0.1744, -0.2630,\n",
      "         -1.3421, -0.1199,  0.2871, -0.1381],\n",
      "        [ 0.3987, -1.2638,  0.5839,  0.1382, -0.6616, -0.7334, -0.7295,  0.6604,\n",
      "          0.7898, -0.1731,  0.1221,  0.4239,  0.0084, -0.2746,  0.1778, -0.2839,\n",
      "         -1.3654, -0.1160,  0.2776, -0.1412],\n",
      "        [ 0.3659, -1.2301,  0.5562,  0.0977, -0.6595, -0.7049, -0.7093,  0.6193,\n",
      "          0.7657, -0.1802,  0.1258,  0.4215,  0.0114, -0.2615,  0.1713, -0.2418,\n",
      "         -1.3187, -0.1239,  0.2967, -0.1356],\n",
      "        [ 0.4241, -1.2897,  0.6049,  0.1699, -0.6632, -0.7557, -0.7448,  0.6923,\n",
      "          0.8094, -0.1663,  0.1188,  0.4250,  0.0076, -0.2835,  0.1833, -0.3164,\n",
      "         -1.4018, -0.1102,  0.2632, -0.1471],\n",
      "        [ 0.4212, -1.2867,  0.6026,  0.1663, -0.6630, -0.7532, -0.7431,  0.6886,\n",
      "          0.8070, -0.1672,  0.1192,  0.4250,  0.0076, -0.2826,  0.1826, -0.3127,\n",
      "         -1.3976, -0.1109,  0.2648, -0.1462],\n",
      "        [ 0.3674, -1.2316,  0.5575,  0.0995, -0.6596, -0.7062, -0.7102,  0.6211,\n",
      "          0.7668, -0.1799,  0.1256,  0.4216,  0.0112, -0.2622,  0.1716, -0.2438,\n",
      "         -1.3209, -0.1236,  0.2959, -0.1359],\n",
      "        [ 0.3805, -1.2451,  0.5686,  0.1157, -0.6604, -0.7176, -0.7183,  0.6375,\n",
      "          0.7762, -0.1774,  0.1243,  0.4227,  0.0097, -0.2676,  0.1740, -0.2606,\n",
      "         -1.3394, -0.1203,  0.2881, -0.1378],\n",
      "        [ 0.3836, -1.2483,  0.5712,  0.1195, -0.6606, -0.7203, -0.7202,  0.6414,\n",
      "          0.7785, -0.1767,  0.1239,  0.4229,  0.0095, -0.2688,  0.1747, -0.2646,\n",
      "         -1.3439, -0.1196,  0.2863, -0.1383],\n",
      "        [ 0.4222, -1.2878,  0.6034,  0.1675, -0.6631, -0.7541, -0.7437,  0.6899,\n",
      "          0.8078, -0.1669,  0.1191,  0.4250,  0.0076, -0.2829,  0.1828, -0.3140,\n",
      "         -1.3991, -0.1106,  0.2642, -0.1465],\n",
      "        [ 0.4006, -1.2658,  0.5855,  0.1407, -0.6617, -0.7352, -0.7307,  0.6628,\n",
      "          0.7913, -0.1727,  0.1219,  0.4240,  0.0083, -0.2753,  0.1782, -0.2864,\n",
      "         -1.3682, -0.1155,  0.2765, -0.1416],\n",
      "        [ 0.3968, -1.2618,  0.5823,  0.1359, -0.6614, -0.7318, -0.7283,  0.6580,\n",
      "          0.7883, -0.1736,  0.1224,  0.4238,  0.0085, -0.2739,  0.1773, -0.2815,\n",
      "         -1.3626, -0.1164,  0.2787, -0.1408],\n",
      "        [ 0.3673, -1.2316,  0.5574,  0.0994, -0.6596, -0.7061, -0.7102,  0.6210,\n",
      "          0.7667, -0.1799,  0.1257,  0.4216,  0.0112, -0.2621,  0.1715, -0.2437,\n",
      "         -1.3207, -0.1236,  0.2959, -0.1358],\n",
      "        [ 0.3663, -1.2305,  0.5565,  0.0982, -0.6595, -0.7053, -0.7095,  0.6197,\n",
      "          0.7660, -0.1801,  0.1258,  0.4215,  0.0114, -0.2617,  0.1713, -0.2423,\n",
      "         -1.3193, -0.1238,  0.2965, -0.1357],\n",
      "        [ 0.3805, -1.2451,  0.5686,  0.1157, -0.6604, -0.7176, -0.7183,  0.6375,\n",
      "          0.7762, -0.1774,  0.1243,  0.4227,  0.0097, -0.2676,  0.1740, -0.2606,\n",
      "         -1.3394, -0.1203,  0.2881, -0.1377],\n",
      "        [ 0.3287, -1.1915,  0.5239,  0.0519, -0.6573, -0.6728, -0.6859,  0.5725,\n",
      "          0.7396, -0.1861,  0.1292,  0.4175,  0.0173, -0.2449,  0.1647, -0.1936,\n",
      "         -1.2662, -0.1337,  0.3192, -0.1318],\n",
      "        [ 0.4100, -1.2754,  0.5934,  0.1523, -0.6623, -0.7434, -0.7364,  0.6746,\n",
      "          0.7984, -0.1703,  0.1207,  0.4245,  0.0078, -0.2787,  0.1801, -0.2984,\n",
      "         -1.3816, -0.1134,  0.2711, -0.1436],\n",
      "        [ 0.3860, -1.2508,  0.5732,  0.1225, -0.6608, -0.7224, -0.7217,  0.6445,\n",
      "          0.7804, -0.1760,  0.1236,  0.4231,  0.0094, -0.2697,  0.1752, -0.2677,\n",
      "         -1.3473, -0.1190,  0.2849, -0.1388],\n",
      "        [ 0.4523, -1.3181,  0.6277,  0.2052, -0.6652, -0.7806, -0.7615,  0.7276,\n",
      "          0.8321, -0.1571,  0.1145,  0.4254,  0.0086, -0.2920,  0.1900, -0.3520,\n",
      "         -1.4425, -0.1044,  0.2477, -0.1555]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atlantic-chess",
   "metadata": {},
   "source": [
    "# A3C Code\n",
    "- Simple A3C code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "rational-image",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def v_wrap(np_array, dtype=np.float32):\n",
    "    if np_array.dtype != dtype:\n",
    "        np_array = np_array.astype(dtype)\n",
    "    return torch.from_numpy(np_array)\n",
    "\n",
    "\n",
    "def set_init(layers):\n",
    "    for layer in layers:\n",
    "        nn.init.normal_(layer.weight, mean=0., std=0.1)\n",
    "        nn.init.constant_(layer.bias, 0.)\n",
    "\n",
    "\n",
    "def push_and_pull(opt, lnet, gnet, done, s_, bs, buffer_action, buffer_reward, gamma):\n",
    "    if done:\n",
    "        v_s_ = 0.               # terminal\n",
    "    else:\n",
    "        v_s_ = lnet.forward(v_wrap(s_[None, :]))[-1].data.numpy()[0, 0]\n",
    "\n",
    "    buffer_v_target = []\n",
    "    for r in buffer_reward[::-1]:    # reverse buffer r\n",
    "        v_s_ = r + gamma * v_s_\n",
    "        buffer_v_target.append(v_s_)\n",
    "    buffer_v_target.reverse()\n",
    "    loss = lnet.loss_func(\n",
    "        v_wrap(np.vstack(bs)),\n",
    "        v_wrap(np.array(buffer_action), dtype=np.int64) if buffer_action[0].dtype == np.int64 else v_wrap(np.vstack(buffer_action)),\n",
    "        v_wrap(np.array(buffer_v_target)[:, None]))\n",
    "\n",
    "    # calculate local gradients and push local parameters to global\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    for lp, gp in zip(lnet.parameters(), gnet.parameters()):\n",
    "        gp._grad = lp.grad\n",
    "    opt.step()\n",
    "\n",
    "    # pull global parameters\n",
    "    lnet.load_state_dict(gnet.state_dict())\n",
    "\n",
    "\n",
    "def record(global_ep, global_ep_r, ep_r, res_queue, name):\n",
    "    with global_ep.get_lock():\n",
    "        global_ep.value += 1\n",
    "    with global_ep_r.get_lock():\n",
    "        if global_ep_r.value == 0.:\n",
    "            global_ep_r.value = ep_r\n",
    "        else:\n",
    "            global_ep_r.value = global_ep_r.value * 0.99 + ep_r * 0.01\n",
    "    res_queue.put(global_ep_r.value)\n",
    "    print(\n",
    "        name,\n",
    "        \"Ep:\", global_ep.value,\n",
    "        \"| Ep_r: %.0f\" % global_ep_r.value,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "committed-texas",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SharedAdam(torch.optim.Adam):\n",
    "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.99), eps=1e-8,\n",
    "                 weight_decay=0):\n",
    "        super(SharedAdam, self).__init__(params, lr=lr, betas=betas, eps=eps, weight_decay=weight_decay)\n",
    "        # State initialization\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                state = self.state[p]\n",
    "                state['step'] = 0\n",
    "                state['exp_avg'] = torch.zeros_like(p.data)\n",
    "                state['exp_avg_sq'] = torch.zeros_like(p.data)\n",
    "\n",
    "                # share in memory\n",
    "                state['exp_avg'].share_memory_()\n",
    "                state['exp_avg_sq'].share_memory_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "vocal-luther",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.multiprocessing as mp\n",
    "import gym\n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "UPDATE_GLOBAL_ITER = 5\n",
    "GAMMA = 0.9\n",
    "MAX_EP = 3000\n",
    "\n",
    "env = gym.make('CartPole-v0')\n",
    "N_S = env.observation_space.shape[0]\n",
    "N_A = env.action_space.n\n",
    "\n",
    "print(N_S, N_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "surrounded-patient",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, s_dim, a_dim):\n",
    "        super(Net, self).__init__()\n",
    "        self.s_dim = s_dim\n",
    "        self.a_dim = a_dim\n",
    "        self.pi1 = nn.Linear(s_dim, 128)\n",
    "        self.pi2 = nn.Linear(128, a_dim)\n",
    "        self.v1 = nn.Linear(s_dim, 128)\n",
    "        self.v2 = nn.Linear(128, 1)\n",
    "        set_init([self.pi1, self.pi2, self.v1, self.v2])\n",
    "        self.distribution = torch.distributions.Categorical\n",
    "\n",
    "    def forward(self, x):\n",
    "        pi1 = torch.tanh(self.pi1(x))\n",
    "        logits = self.pi2(pi1)\n",
    "        v1 = torch.tanh(self.v1(x))\n",
    "        values = self.v2(v1)\n",
    "        return logits, values\n",
    "\n",
    "    def choose_action(self, s):\n",
    "        self.eval()\n",
    "        logits, _ = self.forward(s)\n",
    "        prob = F.softmax(logits, dim=1).data\n",
    "        m = self.distribution(prob)\n",
    "        return m.sample().numpy()[0]\n",
    "\n",
    "    def loss_func(self, s, a, v_t):\n",
    "        self.train()\n",
    "        logits, values = self.forward(s)\n",
    "        td = v_t - values\n",
    "        c_loss = td.pow(2)\n",
    "        \n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        m = self.distribution(probs)\n",
    "        exp_v = m.log_prob(a) * td.detach().squeeze()\n",
    "        a_loss = -exp_v\n",
    "        total_loss = (c_loss + a_loss).mean()\n",
    "        return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "derived-girlfriend",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Worker(mp.Process):\n",
    "    def __init__(self, gnet, opt, global_ep, global_ep_r, res_queue, name):\n",
    "        super(Worker, self).__init__()\n",
    "        self.name = 'w%02i' % name\n",
    "        self.g_ep, self.g_ep_r, self.res_queue = global_ep, global_ep_r, res_queue\n",
    "        self.gnet, self.opt = gnet, opt\n",
    "        self.lnet = Net(N_S, N_A)           # local network\n",
    "        self.env = gym.make('CartPole-v0').unwrapped\n",
    "\n",
    "    def run(self):\n",
    "        total_step = 1\n",
    "        while self.g_ep.value < MAX_EP:\n",
    "            s = self.env.reset()\n",
    "            buffer_s, buffer_action, buffer_reward = [], [], []\n",
    "            ep_r = 0.\n",
    "            while True:\n",
    "#                 if self.name == 'w00':\n",
    "#                     self.env.render()\n",
    "                print(s)\n",
    "                a = self.lnet.choose_action(v_wrap(s[None, :]))\n",
    "                print(s[None, :])\n",
    "                print(v_wrap(s[None, :]))\n",
    "                s_, r, done, _ = self.env.step(a)\n",
    "                if done: r = -1\n",
    "                ep_r += r\n",
    "                buffer_action.append(a)\n",
    "                buffer_s.append(s)\n",
    "                buffer_reward.append(r)\n",
    "\n",
    "                if total_step % UPDATE_GLOBAL_ITER == 0 or done:  # update global and assign to local net\n",
    "                    # sync\n",
    "                    push_and_pull(self.opt, self.lnet, self.gnet, done, s_, buffer_s, buffer_action, buffer_reward, GAMMA)\n",
    "                    buffer_s, buffer_action, buffer_reward = [], [], []\n",
    "\n",
    "                    if done:  # done and print information\n",
    "                        record(self.g_ep, self.g_ep_r, ep_r, self.res_queue, self.name)\n",
    "                        break\n",
    "                s = s_\n",
    "                total_step += 1\n",
    "        self.res_queue.put(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "sealed-observation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n",
      "[-0.00884561  0.00451411  0.02020056 -0.04959281]\n",
      "[[-0.00884561  0.00451411  0.02020056 -0.04959281]][-0.03547944  0.03127026 -0.03322896 -0.00991521]\n",
      "\n",
      "tensor([[-0.0088,  0.0045,  0.0202, -0.0496]])[0.03297781 0.03484544 0.03839904 0.0296429 ]\n",
      "[[-0.03547944  0.03127026 -0.03322896 -0.00991521]]\n",
      "\n",
      "[-0.00875533 -0.19089158  0.01920871  0.2493945 ]\n",
      "[[0.03297781 0.03484544 0.03839904 0.0296429 ]]tensor([[-0.0355,  0.0313, -0.0332, -0.0099]])[[-0.00875533 -0.19089158  0.01920871  0.2493945 ]]\n",
      "\n",
      "[-0.04561013 -0.04901802  0.02548184 -0.01022353]\n",
      "[-0.03485403 -0.16335977 -0.03342727  0.27210117]\n",
      "\n",
      "tensor([[-0.0088, -0.1909,  0.0192,  0.2494]])tensor([[0.0330, 0.0348, 0.0384, 0.0296]])\n",
      "\n",
      "[[-0.03485403 -0.16335977 -0.03342727  0.27210117]][-0.01257316 -0.38628251  0.0241966   0.54807383][[-0.04561013 -0.04901802  0.02548184 -0.01022353]][ 0.03367472 -0.16080554  0.0389919   0.33418957]\n",
      "\n",
      "\n",
      "\n",
      "tensor([[-0.0349, -0.1634, -0.0334,  0.2721]])[[-0.01257316 -0.38628251  0.0241966   0.54807383]][[ 0.03367472 -0.16080554  0.0389919   0.33418957]][-0.00755387 -0.01521488  0.03159329  0.01690139]\n",
      "\n",
      "\n",
      "\n",
      "tensor([[-0.0126, -0.3863,  0.0242,  0.5481]])[-0.03812123 -0.35798919 -0.02798524  0.55405642]\n",
      "tensor([[-0.0456, -0.0490,  0.0255, -0.0102]])\n",
      "tensor([[ 0.0337, -0.1608,  0.0390,  0.3342]])[-0.02029881 -0.19150869  0.03515807  0.26311173]\n",
      "\n",
      "[[-0.00755387 -0.01521488  0.03159329  0.01690139]]\n",
      "[[-0.03812123 -0.35798919 -0.02798524  0.55405642]]\n",
      "[-0.04659049 -0.24449597  0.02527737  0.29038906][ 0.03045861 -0.35646012  0.04567569  0.63890909]\n",
      "\n",
      "\n",
      "[ 0.04208942 -0.03883313 -0.03299809 -0.02004093]\n",
      "tensor([[-0.0076, -0.0152,  0.0316,  0.0169]])[[-0.02029881 -0.19150869  0.03515807  0.26311173]]tensor([[-0.0381, -0.3580, -0.0280,  0.5541]])[[ 0.03045861 -0.35646012  0.04567569  0.63890909]][[-0.04659049 -0.24449597  0.02527737  0.29038906]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[-0.04528101 -0.16248568 -0.01690411  0.25268939][-0.00785816 -0.21077534  0.03193131  0.31938258]tensor([[ 0.0305, -0.3565,  0.0457,  0.6389]])\n",
      "tensor([[-0.0466, -0.2445,  0.0253,  0.2904]])tensor([[-0.0203, -0.1915,  0.0352,  0.2631]])\n",
      "\n",
      "\n",
      "\n",
      "[ 0.02332941 -0.16200379  0.05845387  0.3609528 ][-0.05148041 -0.43996907  0.03108515  0.59093579][[-0.04528101 -0.16248568 -0.01690411  0.25268939]][[ 0.04208942 -0.03883313 -0.03299809 -0.02004093]][-0.02412899 -0.38711438  0.04042031  0.56667329]\n",
      "\n",
      "[[-0.00785816 -0.21077534  0.03193131  0.31938258]]\n",
      "\n",
      "\n",
      "\n",
      "[[-0.05148041 -0.43996907  0.03108515  0.59093579]][[ 0.02332941 -0.16200379  0.05845387  0.3609528 ]]tensor([[-0.0453, -0.1625, -0.0169,  0.2527]])\n",
      "[[-0.02412899 -0.38711438  0.04042031  0.56667329]]\n",
      "\n",
      "tensor([[ 0.0421, -0.0388, -0.0330, -0.0200]])tensor([[-0.0079, -0.2108,  0.0319,  0.3194]])\n",
      "tensor([[-0.0515, -0.4400,  0.0311,  0.5909]])tensor([[ 0.0233, -0.1620,  0.0585,  0.3610]])\n",
      "\n",
      "[-0.04853072 -0.35736223 -0.01185033  0.53999288]\n",
      "\n",
      "tensor([[-0.0241, -0.3871,  0.0404,  0.5667]])[-0.01207367 -0.40633716  0.03831897  0.62196198]\n",
      "[ 0.04131276 -0.23346669 -0.03339891  0.26205081][-0.06027979 -0.24529581  0.04290387  0.30820453]\n",
      "[ 0.02008933 -0.3579058   0.06567293  0.67147958]\n",
      "\n",
      "[[-0.04853072 -0.35736223 -0.01185033  0.53999288]][-0.02615273  0.01245178 -0.019305    0.02557196]\n",
      "\n",
      "\n",
      "\n",
      "[[-0.06027979 -0.24529581  0.04290387  0.30820453]][[ 0.02008933 -0.3579058   0.06567293  0.67147958]]tensor([[-0.0485, -0.3574, -0.0119,  0.5400]])[[-0.01207367 -0.40633716  0.03831897  0.62196198]][[ 0.04131276 -0.23346669 -0.03339891  0.26205081]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tensor([[ 0.0201, -0.3579,  0.0657,  0.6715]])tensor([[-0.0603, -0.2453,  0.0429,  0.3082]])\n",
      "tensor([[-0.0121, -0.4063,  0.0383,  0.6220]])tensor([[ 0.0413, -0.2335, -0.0334,  0.2621]])[[-0.02615273  0.01245178 -0.019305    0.02557196]]\n",
      "\n",
      "\n",
      "\n",
      "[-0.06518571 -0.44100199  0.04906796  0.61410353][-0.02020041 -0.21177066  0.0507582   0.34158949]\n",
      "[ 0.03664342 -0.42809637 -0.02815789  0.54401505]\n",
      "tensor([[-0.0262,  0.0125, -0.0193,  0.0256]])\n",
      "\n",
      "[[-0.02020041 -0.21177066  0.0507582   0.34158949]][[-0.06518571 -0.44100199  0.04906796  0.61410353]][ 0.02415054 -0.01642836  0.01612394 -0.02734417]\n",
      "\n",
      "[-0.02590369 -0.18238808 -0.01879356  0.31210197]\n",
      "[[ 0.03664342 -0.42809637 -0.02815789  0.54401505]]\n",
      "tensor([[-0.0202, -0.2118,  0.0508,  0.3416]])\n",
      "tensor([[-0.0652, -0.4410,  0.0491,  0.6141]])\n",
      "\n",
      "[[-0.02590369 -0.18238808 -0.01879356  0.31210197]][-0.02443583 -0.40757665  0.05758999  0.64983671]tensor([[ 0.0366, -0.4281, -0.0282,  0.5440]])\n",
      "\n",
      "[[ 0.02415054 -0.01642836  0.01612394 -0.02734417]]\n",
      "\n",
      "tensor([[-0.0259, -0.1824, -0.0188,  0.3121]])[ 0.02808149 -0.23259027 -0.01727759  0.24259483][[-0.02443583 -0.40757665  0.05758999  0.64983671]]\n",
      "\n",
      "\n",
      "[-0.02955146 -0.37723732 -0.01255152  0.59879923]tensor([[ 0.0242, -0.0164,  0.0161, -0.0273]])\n",
      "\n",
      "tensor([[-0.0244, -0.4076,  0.0576,  0.6498]])[[ 0.02808149 -0.23259027 -0.01727759  0.24259483]]\n",
      "\n",
      "[[-0.02955146 -0.37723732 -0.01255152  0.59879923]][ 0.02382198 -0.21177778  0.01557706  0.27038212][-0.03868677 -0.0119883   0.04966045 -0.02312588]\n",
      "\n",
      "tensor([[ 0.0281, -0.2326, -0.0173,  0.2426]])\n",
      "\n",
      "tensor([[-0.0296, -0.3772, -0.0126,  0.5988]])[[ 0.02382198 -0.21177778  0.01557706  0.27038212]]\n",
      "[ 0.02342969 -0.42746123 -0.01242569  0.52977827]\n",
      "\n",
      "[-0.0370962  -0.18194202 -0.00057554  0.3021893 ]tensor([[ 0.0238, -0.2118,  0.0156,  0.2704]])\n",
      "\n",
      "[[ 0.02342969 -0.42746123 -0.01242569  0.52977827]][[-0.03868677 -0.0119883   0.04966045 -0.02312588]][[-0.0370962  -0.18194202 -0.00057554  0.3021893 ]][ 0.01958642 -0.40711852  0.0209847   0.56793714]\n",
      "\n",
      "\n",
      "\n",
      "tensor([[ 0.0234, -0.4275, -0.0124,  0.5298]])tensor([[-0.0371, -0.1819, -0.0006,  0.3022]])[ 0.04844836  0.02533969 -0.02262375 -0.03808612]\n",
      "\n",
      "[[ 0.01958642 -0.40711852  0.0209847   0.56793714]]tensor([[-0.0387, -0.0120,  0.0497, -0.0231]])[-0.04073504 -0.37705576  0.00546825  0.59469066]\n",
      "\n",
      "\n",
      "\n",
      "[-0.03892654 -0.20778596  0.04919794  0.2848027 ]\n",
      "tensor([[ 0.0196, -0.4071,  0.0210,  0.5679]])[[-0.04073504 -0.37705576  0.00546825  0.59469066]]\n",
      "[[ 0.04844836  0.02533969 -0.02262375 -0.03808612]][[-0.03892654 -0.20778596  0.04919794  0.2848027 ]]\n",
      "[ 0.01144405 -0.2122971   0.03234345  0.28193841]\n",
      "\n",
      "\n",
      "tensor([[-0.0407, -0.3771,  0.0055,  0.5947]])\n",
      "tensor([[-0.0389, -0.2078,  0.0492,  0.2848]])tensor([[ 0.0484,  0.0253, -0.0226, -0.0381]])\n",
      "[[ 0.01144405 -0.2122971   0.03234345  0.28193841]]\n",
      "[ 0.00792096  0.01049064  0.02825469 -0.0315635 ][-0.04308226 -0.4035738   0.05489399  0.59258748]\n",
      "\n",
      "\n",
      "[ 0.04895515 -0.16945065 -0.02338547  0.24737381]\n",
      "tensor([[ 0.0114, -0.2123,  0.0323,  0.2819]])[[-0.04308226 -0.4035738   0.05489399  0.59258748]]\n",
      "\n",
      "[ 0.00719811 -0.40786511  0.03798221  0.58464431][[ 0.04895515 -0.16945065 -0.02338547  0.24737381]][[ 0.00792096  0.01049064  0.02825469 -0.0315635 ]]tensor([[-0.0431, -0.4036,  0.0549,  0.5926]])\n",
      "\n",
      "\n",
      "\n",
      "[-0.05115373 -0.20926153  0.06674574  0.31768884][[ 0.00719811 -0.40786511  0.03798221  0.58464431]]tensor([[ 0.0490, -0.1695, -0.0234,  0.2474]])tensor([[ 0.0079,  0.0105,  0.0283, -0.0316]])\n",
      "\n",
      "\n",
      "\n",
      "tensor([[ 0.0072, -0.4079,  0.0380,  0.5846]])\n",
      "[ 0.04556614 -0.36423095 -0.018438    0.53258966][ 0.00813077 -0.18502486  0.02762342  0.26989847]\n",
      "[[-0.05115373 -0.20926153  0.06674574  0.31768884]][-0.0065212   0.03505913 -0.03612938  0.00386353]\n",
      "\n",
      "\n",
      "[[ 0.04556614 -0.36423095 -0.018438    0.53258966]]tensor([[-0.0512, -0.2093,  0.0667,  0.3177]])[[ 0.00813077 -0.18502486  0.02762342  0.26989847]]\n",
      "\n",
      "\n",
      "tensor([[ 0.0456, -0.3642, -0.0184,  0.5326]])[-0.05533896 -0.40526751  0.07309952  0.63065183]\n",
      "\n",
      "[[-0.0065212   0.03505913 -0.03612938  0.00386353]]tensor([[ 0.0081, -0.1850,  0.0276,  0.2699]])[ 0.03828152 -0.16885459 -0.0077862   0.23415447]\n",
      "\n",
      "[[-0.05533896 -0.40526751  0.07309952  0.63065183]]\n",
      "[-0.04943136 -0.01073519 -0.04962296  0.02431898]\n",
      "[ 0.00443027 -0.3805299   0.03302139  0.5711644 ]\n",
      "tensor([[-0.0065,  0.0351, -0.0361,  0.0039]])[[ 0.03828152 -0.16885459 -0.0077862   0.23415447]]\n",
      "\n",
      "\n",
      "tensor([[-0.0553, -0.4053,  0.0731,  0.6307]])\n",
      "[-0.00582002 -0.15952654 -0.03605211  0.28493184]tensor([[ 0.0383, -0.1689, -0.0078,  0.2342]])[[ 0.00443027 -0.3805299   0.03302139  0.5711644 ]]\n",
      "\n",
      "[[-0.04943136 -0.01073519 -0.04962296  0.02431898]]\n",
      "\n",
      "[ 0.03490443 -0.36386443 -0.00310311  0.52437125][[-0.00582002 -0.15952654 -0.03605211  0.28493184]]\n",
      "\n",
      "tensor([[ 0.0044, -0.3805,  0.0330,  0.5712]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0494, -0.0107, -0.0496,  0.0243]])[[ 0.03490443 -0.36386443 -0.00310311  0.52437125]]tensor([[-0.0058, -0.1595, -0.0361,  0.2849]])[-0.00318032 -0.18588619  0.04444468  0.28906454]\n",
      "\n",
      "[-0.01240207  0.00416165  0.03688031 -0.02538796]\n",
      "\n",
      "[-0.04964606 -0.20511167 -0.04913658  0.30094164]tensor([[ 0.0349, -0.3639, -0.0031,  0.5244]])[-0.00901055 -0.35411626 -0.03035348  0.56602972]\n",
      "\n",
      "\n",
      "\n",
      "[[-0.00318032 -0.18588619  0.04444468  0.28906454]]\n",
      "[[-0.04964606 -0.20511167 -0.04913658  0.30094164]]tensor([[-0.0032, -0.1859,  0.0444,  0.2891]])[[-0.00901055 -0.35411626 -0.03035348  0.56602972]]\n",
      "\n",
      "\n",
      "[-0.00689805 -0.38161282  0.05022597  0.59542698]tensor([[-0.0496, -0.2051, -0.0491,  0.3009]])\n",
      "[[-0.01240207  0.00416165  0.03688031 -0.02538796]]\n",
      "tensor([[-0.0090, -0.3541, -0.0304,  0.5660]])[[-0.00689805 -0.38161282  0.05022597  0.59542698]]\n",
      "\n",
      "\n",
      "[-0.05374829 -0.3995001  -0.04311775  0.577732  ]tensor([[-0.0069, -0.3816,  0.0502,  0.5954]])\n",
      "\n",
      "[-0.01609287 -0.15858193 -0.01903288  0.26394077][[-0.05374829 -0.3995001  -0.04311775  0.577732  ]]tensor([[-0.0124,  0.0042,  0.0369, -0.0254]])[-0.04790314 -0.01821552  0.04914747  0.04835476]\n",
      "\n",
      "\n",
      "\n",
      "[-0.01231884 -0.19146926  0.03637255  0.27869921]\n",
      "tensor([[-0.0537, -0.3995, -0.0431,  0.5777]])[[-0.01609287 -0.15858193 -0.01903288  0.26394077]]\n",
      "\n",
      "[[-0.01231884 -0.19146926  0.03637255  0.27869921]]tensor([[-0.0161, -0.1586, -0.0190,  0.2639]])[-0.06173829 -0.20380118 -0.03156311  0.27178377]\n",
      "[[-0.04790314 -0.01821552  0.04914747  0.04835476]]\n",
      "\n",
      "\n",
      "[-0.01926451 -0.35342711 -0.01375407  0.55056029]tensor([[-0.0123, -0.1915,  0.0364,  0.2787]])\n",
      "\n",
      "[[-0.01926451 -0.35342711 -0.01375407  0.55056029]][[-0.06173829 -0.20380118 -0.03156311  0.27178377]][-0.01614822 -0.3870907   0.04194653  0.58262846]\n",
      "tensor([[-0.0479, -0.0182,  0.0491,  0.0484]])\n",
      "\n",
      "\n",
      "tensor([[-0.0193, -0.3534, -0.0138,  0.5506]])[-0.00830791 -0.00515354  0.03749368  0.01997492]\n",
      "tensor([[-0.0617, -0.2038, -0.0316,  0.2718]])[-0.04826746 -0.21400649  0.05011457  0.35613014]\n",
      "[[-0.01614822 -0.3870907   0.04194653  0.58262846]]\n",
      "\n",
      "\n",
      "tensor([[-0.0161, -0.3871,  0.0419,  0.5826]])[[-0.04826746 -0.21400649  0.05011457  0.35613014]][-0.06581432 -0.39845886 -0.02612743  0.55434685]\n",
      "\n",
      "\n",
      "[-0.02389004 -0.19258076  0.0535991   0.30344886][[-0.00830791 -0.00515354  0.03749368  0.01997492]]tensor([[-0.0483, -0.2140,  0.0501,  0.3561]])\n",
      "\n",
      "\n",
      "[[-0.06581432 -0.39845886 -0.02612743  0.55434685]][[-0.02389004 -0.19258076  0.0535991   0.30344886]][-0.05254758 -0.40980381  0.05723717  0.6641849 ]\n",
      "\n",
      "\n",
      "tensor([[-0.0083, -0.0052,  0.0375,  0.0200]])tensor([[-0.0658, -0.3985, -0.0261,  0.5543]])tensor([[-0.0239, -0.1926,  0.0536,  0.3034]])[ 0.00385083  0.03905583  0.04762383 -0.0448576 ]\n",
      "\n",
      "\n",
      "\n",
      "[[-0.05254758 -0.40980381  0.05723717  0.6641849 ]][-0.02774165 -0.38842399  0.05966808  0.61254242][-0.00841098 -0.20079257  0.03789318  0.32424779]\n",
      "\n",
      "\n",
      "[[-0.02774165 -0.38842399  0.05966808  0.61254242]][[-0.00841098 -0.20079257  0.03789318  0.32424779]]tensor([[-0.0525, -0.4098,  0.0572,  0.6642]])\n",
      "\n",
      "\n",
      "[[ 0.00385083  0.03905583  0.04762383 -0.0448576 ]]tensor([[-0.0277, -0.3884,  0.0597,  0.6125]])\n",
      "\n",
      "tensor([[-0.0084, -0.2008,  0.0379,  0.3242]])[-0.06074366 -0.21552283  0.07052087  0.39005921]\n",
      "\n",
      "[-0.01242683 -0.39643301  0.04437813  0.62863572]tensor([[ 0.0039,  0.0391,  0.0476, -0.0449]])[[-0.06074366 -0.21552283  0.07052087  0.39005921]][ 0.02675134  0.02485557 -0.0183491   0.0490477 ]\n",
      "\n",
      "\n",
      "\n",
      "[ 0.00463195 -0.15671553  0.04672668  0.2624626 ][[-0.01242683 -0.39643301  0.04437813  0.62863572]]\n",
      "tensor([[-0.0607, -0.2155,  0.0705,  0.3901]])\n",
      "\n",
      "[[ 0.00463195 -0.15671553  0.04672668  0.2624626 ]][[ 0.02675134  0.02485557 -0.0183491   0.0490477 ]]tensor([[-0.0124, -0.3964,  0.0444,  0.6286]])[-0.06505412 -0.41157112  0.07832206  0.70411667]\n",
      "\n",
      "\n",
      "\n",
      "[-0.02035549 -0.20195758  0.05695085  0.35025266]tensor([[ 0.0046, -0.1567,  0.0467,  0.2625]])tensor([[ 0.0268,  0.0249, -0.0183,  0.0490]])[[-0.06505412 -0.41157112  0.07832206  0.70411667]]\n",
      "\n",
      "\n",
      "\n",
      "[ 0.00149764 -0.35247224  0.05197593  0.56950982][ 0.02724845 -0.16999853 -0.01736815  0.33588532][[-0.02035549 -0.20195758  0.05695085  0.35025266]]tensor([[-0.0651, -0.4116,  0.0783,  0.7041]])[ 0.02230707 -0.02206735 -0.02654059 -0.03230229]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tensor([[-0.0204, -0.2020,  0.0570,  0.3503]])[[ 0.00149764 -0.35247224  0.05197593  0.56950982]][[ 0.02724845 -0.16999853 -0.01736815  0.33588532]]\n",
      "\n",
      "\n",
      "[-0.02439464 -0.39784127  0.0639559   0.66033633]tensor([[ 0.0015, -0.3525,  0.0520,  0.5695]])[[ 0.02230707 -0.02206735 -0.02654059 -0.03230229]]\n",
      "tensor([[ 0.0272, -0.1700, -0.0174,  0.3359]])\n",
      "\n",
      "\n",
      "[-0.00555181 -0.15811631  0.06336613  0.29364366][[-0.02439464 -0.39784127  0.0639559   0.66033633]][ 0.02384848 -0.36486906 -0.01065044  0.62304104]\n",
      "\n",
      "\n",
      "tensor([[ 0.0223, -0.0221, -0.0265, -0.0323]])[[-0.00555181 -0.15811631  0.06336613  0.29364366]]\n",
      "tensor([[-0.0244, -0.3978,  0.0640,  0.6603]])\n",
      "[[ 0.02384848 -0.36486906 -0.01065044  0.62304104]]\n",
      "[ 0.02186572 -0.21679884 -0.02718664  0.25189006]tensor([[-0.0056, -0.1581,  0.0634,  0.2936]])[-0.00170064  0.03682105 -0.04175015 -0.00785304]\n",
      "\n",
      "\n",
      "\n",
      "[-0.00871413 -0.35408177  0.069239    0.60561908]tensor([[ 0.0238, -0.3649, -0.0107,  0.6230]])\n",
      "\n",
      "[[ 0.02186572 -0.21679884 -0.02718664  0.25189006]]\n",
      "[ 0.0165511  -0.16960003  0.00181038  0.32702294][[-0.00170064  0.03682105 -0.04175015 -0.00785304]]\n",
      "\n",
      "[[-0.00871413 -0.35408177  0.069239    0.60561908]]tensor([[ 0.0219, -0.2168, -0.0272,  0.2519]])\n",
      "\n",
      "[[ 0.0165511  -0.16960003  0.00181038  0.32702294]]\n",
      "[ 0.01752974 -0.41152225 -0.02214883  0.53587534]tensor([[-0.0087, -0.3541,  0.0692,  0.6056]])tensor([[-0.0017,  0.0368, -0.0418, -0.0079]])tensor([[ 0.0166, -0.1696,  0.0018,  0.3270]])\n",
      "[ 0.0451416  -0.03793881 -0.01976928 -0.03126907]\n",
      "\n",
      "\n",
      "[ 0.01315909 -0.36474771  0.00835084  0.62027623]\n",
      "\n",
      "[-0.00096422 -0.15767805 -0.04190721  0.2713704 ][[ 0.01752974 -0.41152225 -0.02214883  0.53587534]]\n",
      "\n",
      "[[ 0.01315909 -0.36474771  0.00835084  0.62027623]]\n",
      "[[-0.00096422 -0.15767805 -0.04190721  0.2713704 ]]tensor([[ 0.0175, -0.4115, -0.0221,  0.5359]])tensor([[ 0.0132, -0.3647,  0.0084,  0.6203]])\n",
      "\n",
      "[[ 0.0451416  -0.03793881 -0.01976928 -0.03126907]]\n",
      "[ 0.0092993  -0.21609597 -0.01143133  0.2362966 ]tensor([[-0.0010, -0.1577, -0.0419,  0.2714]])\n",
      "\n",
      "\n",
      "tensor([[ 0.0451, -0.0379, -0.0198, -0.0313]])[[ 0.0092993  -0.21609597 -0.01143133  0.2362966 ]][ 0.00628686 -0.04825652 -0.02958939 -0.011421  ]\n",
      "\n",
      "\n",
      "[-0.00411778 -0.35217773 -0.0364798   0.55054664][ 0.04438283 -0.23277176 -0.02039467  0.25511146]\n",
      "\n",
      "tensor([[ 0.0093, -0.2161, -0.0114,  0.2363]])[[-0.00411778 -0.35217773 -0.0364798   0.55054664]][[ 0.04438283 -0.23277176 -0.02039467  0.25511146]]\n",
      "[[ 0.00628686 -0.04825652 -0.02958939 -0.011421  ]]\n",
      "\n",
      "\n",
      "[ 0.00497738 -0.41105275 -0.0067054   0.52535193]tensor([[-0.0041, -0.3522, -0.0365,  0.5505]])\n",
      "tensor([[ 0.0444, -0.2328, -0.0204,  0.2551]])\n",
      "tensor([[ 0.0063, -0.0483, -0.0296, -0.0114]])\n",
      "[-0.01116133 -0.15656289 -0.02546887  0.24659692]\n",
      "[[ 0.00497738 -0.41105275 -0.0067054   0.52535193]]\n",
      "[ 0.03972739 -0.42759667 -0.01529244  0.54129244]\n",
      "[ 0.00532173 -0.24294189 -0.02981781  0.27178123]\n",
      "[[-0.01116133 -0.15656289 -0.02546887  0.24659692]]tensor([[ 0.0050, -0.4111, -0.0067,  0.5254]])[-0.0325704  -0.00122537 -0.00637684 -0.00462176]\n",
      "\n",
      "\n",
      "\n",
      "[[ 0.03972739 -0.42759667 -0.01529244  0.54129244]]\n",
      "[[ 0.00532173 -0.24294189 -0.02981781  0.27178123]]tensor([[-0.0112, -0.1566, -0.0255,  0.2466]])\n",
      "\n",
      "tensor([[ 0.0397, -0.4276, -0.0153,  0.5413]])tensor([[ 0.0053, -0.2429, -0.0298,  0.2718]])[-0.01429259 -0.35131201 -0.02053693  0.53113882]\n",
      "\n",
      "[[-0.0325704  -0.00122537 -0.00637684 -0.00462176]]\n",
      "[ 0.03117546 -0.23226315 -0.00446659  0.24383062]\n",
      "[ 4.62895358e-04 -4.37625955e-01 -2.43821889e-02  5.54912368e-01]\n",
      "\n",
      "[[-0.01429259 -0.35131201 -0.02053693  0.53113882]]tensor([[-0.0326, -0.0012, -0.0064, -0.0046]])\n",
      "[[ 4.62895358e-04 -4.37625955e-01 -2.43821889e-02  5.54912368e-01]][[ 0.03117546 -0.23226315 -0.00446659  0.24383062]][-0.01438183  0.00532204  0.04834109  0.02043195]\n",
      "\n",
      "\n",
      "\n",
      "tensor([[-0.0143, -0.3513, -0.0205,  0.5311]])[-0.03259491 -0.19625529 -0.00646927  0.28604239]\n",
      "\n",
      "tensor([[ 0.0312, -0.2323, -0.0045,  0.2438]])tensor([[ 4.6290e-04, -4.3763e-01, -2.4382e-02,  5.5491e-01]])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.03259491 -0.19625529 -0.00646927  0.28604239]][ 2.65301958e-02 -4.27321016e-01  4.10024071e-04  5.35101328e-01][[-0.01438183  0.00532204  0.04834109  0.02043195]]\n",
      "[-0.00828962 -0.24217029 -0.01328394  0.25464836]\n",
      "\n",
      "\n",
      "tensor([[-0.0326, -0.1963, -0.0065,  0.2860]])[[ 2.65301958e-02 -4.27321016e-01  4.10024071e-04  5.35101328e-01]]tensor([[-0.0144,  0.0053,  0.0483,  0.0204]])[[-0.00828962 -0.24217029 -0.01328394  0.25464836]]\n",
      "\n",
      "\n",
      "\n",
      "[-0.03652001 -0.39128438 -0.00074842  0.57667796][-0.01427539 -0.19045864  0.04874972  0.32796665]tensor([[ 2.6530e-02, -4.2732e-01,  4.1002e-04,  5.3510e-01]])tensor([[-0.0083, -0.2422, -0.0133,  0.2546]])[-0.03436576 -0.02172756  0.01512299 -0.02009141]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[-0.03652001 -0.39128438 -0.00074842  0.57667796]][-0.01313303 -0.43710008 -0.00819097  0.54311188]\n",
      "\n",
      "[[-0.01427539 -0.19045864  0.04874972  0.32796665]]\n",
      "tensor([[-0.0365, -0.3913, -0.0007,  0.5767]])[[-0.01313303 -0.43710008 -0.00819097  0.54311188]]\n",
      "[[-0.03436576 -0.02172756  0.01512299 -0.02009141]]\n",
      "tensor([[-0.0143, -0.1905,  0.0487,  0.3280]])\n",
      "[-0.0443457  -0.19615195  0.01078514  0.28375935]tensor([[-0.0131, -0.4371, -0.0082,  0.5431]])\n",
      "\n",
      "[-0.01593604  0.02506798  0.0190037  -0.04199147]\n",
      "[-0.01808456 -0.3862395   0.05530906  0.63561578]tensor([[-0.0344, -0.0217,  0.0151, -0.0201]])[[-0.0443457  -0.19615195  0.01078514  0.28375935]]\n",
      "\n",
      "\n",
      "\n",
      "[-0.03480031 -0.21706309  0.01472116  0.27732437]tensor([[-0.0443, -0.1962,  0.0108,  0.2838]])[[-0.01808456 -0.3862395   0.05530906  0.63561578]]\n",
      "\n",
      "\n",
      "[-0.04826874 -0.39142605  0.01646032  0.57982424][[-0.01593604  0.02506798  0.0190037  -0.04199147]]tensor([[-0.0181, -0.3862,  0.0553,  0.6356]])[[-0.03480031 -0.21706309  0.01472116  0.27732437]]\n",
      "\n",
      "\n",
      "\n",
      "[[-0.04826874 -0.39142605  0.01646032  0.57982424]][-0.02580935 -0.1919308   0.06802137  0.36085101]tensor([[-0.0348, -0.2171,  0.0147,  0.2773]])tensor([[-0.0159,  0.0251,  0.0190, -0.0420]])[ 0.01361161  0.01134613 -0.03388849 -0.04440298]\n",
      "\n",
      "\n",
      "\n",
      "tensor([[-0.0483, -0.3914,  0.0165,  0.5798]])\n",
      "\n",
      "[-0.03914157 -0.41239193  0.02026765  0.57461375][-0.01543468 -0.17032125  0.01816387  0.25662621][[-0.02580935 -0.1919308   0.06802137  0.36085101]]\n",
      "\n",
      "\n",
      "tensor([[-0.0258, -0.1919,  0.0680,  0.3609]])[[-0.03914157 -0.41239193  0.02026765  0.57461375]][[ 0.01361161  0.01134613 -0.03388849 -0.04440298]]\n",
      "[[-0.01543468 -0.17032125  0.01816387  0.25662621]]\n",
      "\n",
      "\n",
      "[-0.02964797 -0.38795038  0.07523839  0.67418327]\n",
      "tensor([[-0.0391, -0.4124,  0.0203,  0.5746]])tensor([[-0.0154, -0.1703,  0.0182,  0.2566]])\n",
      "[[-0.02964797 -0.38795038  0.07523839  0.67418327]]tensor([[ 0.0136,  0.0113, -0.0339, -0.0444]])\n",
      "\n",
      "[-0.04738941 -0.21755989  0.03175992  0.28838399]\n",
      "[-0.01884111 -0.36569776  0.0232964   0.55498251]tensor([[-0.0296, -0.3880,  0.0752,  0.6742]])\n",
      "\n",
      "[ 0.01383853 -0.1832739  -0.03477655  0.23739814][-0.03127237 -0.0334737   0.0222425   0.02746124]\n",
      "\n",
      "[[-0.01884111 -0.36569776  0.0232964   0.55498251]][[-0.04738941 -0.21755989  0.03175992  0.28838399]]\n",
      "\n",
      "\n",
      "[[ 0.01383853 -0.1832739  -0.03477655  0.23739814]]\n",
      "tensor([[-0.0188, -0.3657,  0.0233,  0.5550]])tensor([[-0.0474, -0.2176,  0.0318,  0.2884]])tensor([[ 0.0138, -0.1833, -0.0348,  0.2374]])\n",
      "\n",
      "\n",
      "[-0.02615507 -0.17091053  0.03439605  0.26972946][ 0.01017306 -0.37788221 -0.03002859  0.51891185][-0.05174061 -0.41312001  0.0375276   0.59091209][[-0.03127237 -0.0334737   0.0222425   0.02746124]]\n",
      "\n",
      "\n",
      "[[ 0.01017306 -0.37788221 -0.03002859  0.51891185]][[-0.02615507 -0.17091053  0.03439605  0.26972946]]\n",
      "\n",
      "\n",
      "[[-0.05174061 -0.41312001  0.0375276   0.59091209]][-0.00392318 -0.020331   -0.0001372  -0.00699247]\n",
      "tensor([[ 0.0102, -0.3779, -0.0300,  0.5189]])tensor([[-0.0262, -0.1709,  0.0344,  0.2697]])\n",
      "\n",
      "\n",
      "tensor([[-0.0313, -0.0335,  0.0222,  0.0275]])tensor([[-0.0517, -0.4131,  0.0375,  0.5909]])[ 0.00261541 -0.18235065 -0.01965035  0.21691965]\n",
      "[-0.02957328 -0.36650601  0.03979064  0.5730596 ]\n",
      "\n",
      "\n",
      "[-0.03194185 -0.22890745  0.02279172  0.32707811][[ 0.00261541 -0.18235065 -0.01965035  0.21691965]]\n",
      "[[-0.00392318 -0.020331   -0.0001372  -0.00699247]][[-0.02957328 -0.36650601  0.03979064  0.5730596 ]]\n",
      "\n",
      "\n",
      "[[-0.03194185 -0.22890745  0.02279172  0.32707811]]tensor([[ 0.0026, -0.1824, -0.0197,  0.2169]])\n",
      "\n",
      "tensor([[-0.0296, -0.3665,  0.0398,  0.5731]])tensor([[-0.0039, -0.0203, -0.0001, -0.0070]])\n",
      "tensor([[-0.0319, -0.2289,  0.0228,  0.3271]])\n",
      "[-0.0010316  -0.37718625 -0.01531196  0.50333981]\n",
      "[-4.32980445e-03 -2.15450986e-01 -2.77053350e-04  2.85647165e-01]\n",
      "[ 0.02784038 -0.04877869 -0.0318958   0.02460643]\n",
      "\n",
      "[-0.03652    -0.42434635  0.02933329  0.6268605 ][[-0.0010316  -0.37718625 -0.01531196  0.50333981]]\n",
      "\n",
      "[[-4.32980445e-03 -2.15450986e-01 -2.77053350e-04  2.85647165e-01]][[-0.03652    -0.42434635  0.02933329  0.6268605 ]]tensor([[-0.0010, -0.3772, -0.0153,  0.5033]])\n",
      "[[ 0.02784038 -0.04877869 -0.0318958   0.02460643]]\n",
      "\n",
      "\n",
      "tensor([[-4.3298e-03, -2.1545e-01, -2.7705e-04,  2.8565e-01]])tensor([[-0.0365, -0.4243,  0.0293,  0.6269]])\n",
      "\n",
      "[-0.04500692 -0.22964585  0.0418705   0.34355814]tensor([[ 0.0278, -0.0488, -0.0319,  0.0246]])[-0.00863882 -0.41056898  0.00543589  0.5782427 ][-0.04817263  0.01360666 -0.03554841  0.03446239]\n",
      "\n",
      "\n",
      "\n",
      "[ 0.0268648  -0.24342905 -0.03140367  0.30705769]\n",
      "[[-0.04500692 -0.22964585  0.0418705   0.34355814]][[-0.00863882 -0.41056898  0.00543589  0.5782427 ]]\n",
      "[[ 0.0268648  -0.24342905 -0.03140367  0.30705769]]\n",
      "\n",
      "[[-0.04817263  0.01360666 -0.03554841  0.03446239]]tensor([[-0.0086, -0.4106,  0.0054,  0.5782]])tensor([[-0.0450, -0.2296,  0.0419,  0.3436]])\n",
      "tensor([[ 0.0269, -0.2434, -0.0314,  0.3071]])\n",
      "\n",
      "\n",
      "[-0.0168502  -0.21552364  0.01700074  0.28727715][-0.04959984 -0.42533767  0.04874166  0.64914494]tensor([[-0.0482,  0.0136, -0.0355,  0.0345]])\n",
      "\n",
      "[ 0.02199622 -0.43808977 -0.02526251  0.58967364]\n",
      "\n",
      "[[-0.0168502  -0.21552364  0.01700074  0.28727715]][[-0.04959984 -0.42533767  0.04874166  0.64914494]][-0.04790049 -0.18098796 -0.03485916  0.31572088][[ 0.02199622 -0.43808977 -0.02526251  0.58967364]]\n",
      "\n",
      "[0.01477703 0.01876028 0.04390797 0.04564004]\n",
      "\n",
      "\n",
      "tensor([[-0.0169, -0.2155,  0.0170,  0.2873]])tensor([[ 0.0220, -0.4381, -0.0253,  0.5897]])tensor([[-0.0496, -0.4253,  0.0487,  0.6491]])\n",
      "\n",
      "[[-0.04790049 -0.18098796 -0.03485916  0.31572088]]\n",
      "[-0.02116068 -0.41088386  0.02274629  0.58527311][[0.01477703 0.01876028 0.04390797 0.04564004]]\n",
      "[ 0.01323442 -0.24262337 -0.01346904  0.2891412 ]\n",
      "\n",
      "\n",
      "tensor([[-0.0479, -0.1810, -0.0349,  0.3157]])\n",
      "tensor([[0.0148, 0.0188, 0.0439, 0.0456]])[[-0.02116068 -0.41088386  0.02274629  0.58527311]][[ 0.01323442 -0.24262337 -0.01346904  0.2891412 ]]\n",
      "\n",
      "[-0.05152025 -0.37559648 -0.02854474  0.5972098 ]\n",
      "\n",
      "[ 0.01515224 -0.17696289  0.04482077  0.35184662]tensor([[-0.0212, -0.4109,  0.0227,  0.5853]])tensor([[ 0.0132, -0.2426, -0.0135,  0.2891]])\n",
      "[[-0.05152025 -0.37559648 -0.02854474  0.5972098 ]][ 0.02066633  0.02931405  0.02679987 -0.00281932]\n",
      "\n",
      "\n",
      "\n",
      "[ 0.00838196 -0.43755069 -0.00768622  0.57754588][[ 0.01515224 -0.17696289  0.04482077  0.35184662]]\n",
      "tensor([[-0.0515, -0.3756, -0.0285,  0.5972]])\n",
      "\n",
      "[[ 0.00838196 -0.43755069 -0.00768622  0.57754588]][-0.05903218 -0.18008696 -0.01660054  0.29567398]tensor([[ 0.0152, -0.1770,  0.0448,  0.3518]])\n",
      "\n",
      "[[ 0.02066633  0.02931405  0.02679987 -0.00281932]]\n",
      "\n",
      "tensor([[ 0.0084, -0.4376, -0.0077,  0.5775]])[ 0.01161298 -0.37269261  0.0518577   0.65831925][[-0.05903218 -0.18008696 -0.01660054  0.29567398]]\n",
      "\n",
      "\n",
      "tensor([[ 0.0207,  0.0293,  0.0268, -0.0028]])\n",
      "tensor([[-0.0590, -0.1801, -0.0166,  0.2957]])[[ 0.01161298 -0.37269261  0.0518577   0.65831925]]\n",
      "[ 0.02125261 -0.16618179  0.02674349  0.29819736]\n",
      "\n",
      "[-0.00296904  0.03098399  0.00987179 -0.00814715][-0.06263392 -0.37496836 -0.01068707  0.58307547]\n",
      "\n",
      "[[ 0.02125261 -0.16618179  0.02674349  0.29819736]]\n",
      "tensor([[ 0.0116, -0.3727,  0.0519,  0.6583]])[[-0.06263392 -0.37496836 -0.01068707  0.58307547]]\n",
      "\n",
      "tensor([[ 0.0213, -0.1662,  0.0267,  0.2982]])[[-0.00296904  0.03098399  0.00987179 -0.00814715]][ 0.00415913 -0.17832933  0.06502409  0.3824056 ]\n",
      "tensor([[-0.0626, -0.3750, -0.0107,  0.5831]])\n",
      "\n",
      "[ 0.01792897 -0.36167456  0.03270743  0.59919329][-0.01128557 -0.02748694  0.02480026  0.04939495]\n",
      "\n",
      "\n",
      "[[ 0.00415913 -0.17832933  0.06502409  0.3824056 ]]\n",
      "tensor([[-0.0030,  0.0310,  0.0099, -0.0081]])[[ 0.01792897 -0.36167456  0.03270743  0.59919329]]\n",
      "\n",
      "tensor([[ 0.0042, -0.1783,  0.0650,  0.3824]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.01128557 -0.02748694  0.02480026  0.04939495]]tensor([[ 0.0179, -0.3617,  0.0327,  0.5992]])\n",
      "[-0.00234936 -0.16427813  0.00970885  0.28763403][ 5.92540325e-04 -3.74311383e-01  7.26721970e-02  6.94861021e-01]\n",
      "\n",
      "\n",
      "[ 0.01069548 -0.16702512  0.0446913   0.31698957]tensor([[-0.0113, -0.0275,  0.0248,  0.0494]])\n",
      "\n",
      "[[ 5.92540325e-04 -3.74311383e-01  7.26721970e-02  6.94861021e-01]][[-0.00234936 -0.16427813  0.00970885  0.28763403]][-0.01183531 -0.22295557  0.02578816  0.34979825]\n",
      "[[ 0.01069548 -0.16702512  0.0446913   0.31698957]]\n",
      "[ 0.00679903 -0.01425005 -0.02309682 -0.03427595]\n",
      "\n",
      "tensor([[-0.0023, -0.1643,  0.0097,  0.2876]])\n",
      "tensor([[ 5.9254e-04, -3.7431e-01,  7.2672e-02,  6.9486e-01]])\n",
      "[[-0.01183531 -0.22295557  0.02578816  0.34979825]]\n",
      "tensor([[ 0.0107, -0.1670,  0.0447,  0.3170]])\n",
      "[-0.00563492 -0.35953719  0.01546153  0.58336316]\n",
      "tensor([[-0.0118, -0.2230,  0.0258,  0.3498]])\n",
      "[ 0.00735498 -0.36275419  0.05103109  0.62342489]\n",
      "[[ 0.00679903 -0.01425005 -0.02309682 -0.03427595]]\n",
      "[-0.01629442 -0.4184346   0.03278412  0.65050019][[-0.00563492 -0.35953719  0.01546153  0.58336316]]\n",
      "\n",
      "\n",
      "[[ 0.00735498 -0.36275419  0.05103109  0.62342489]][[-0.01629442 -0.4184346   0.03278412  0.65050019]]\n",
      "tensor([[-0.0056, -0.3595,  0.0155,  0.5834]])\n",
      "\n",
      "tensor([[-0.0163, -0.4184,  0.0328,  0.6505]])tensor([[ 0.0068, -0.0143, -0.0231, -0.0343]])\n",
      "tensor([[ 0.0074, -0.3628,  0.0510,  0.6234]])[-0.01282567 -0.16463522  0.02712879  0.29559066]\n",
      "[-0.02466311 -0.22378426  0.04579413  0.36831838]\n",
      "\n",
      "\n",
      "[ 0.00651403 -0.2090333  -0.02378234  0.25103114][[-0.01282567 -0.16463522  0.02712879  0.29559066]][[-0.02466311 -0.22378426  0.04579413  0.36831838]]\n",
      "\n",
      "\n",
      "\n",
      "[-0.01611837 -0.3601332   0.03304061  0.59670463]tensor([[ 0.0065, -0.2090, -0.0238,  0.2510]])[-0.0291388  -0.41952597  0.0531605   0.6750819 ]tensor([[-0.0128, -0.1646,  0.0271,  0.2956]])tensor([[-0.0247, -0.2238,  0.0458,  0.3683]])[[ 0.00651403 -0.2090333  -0.02378234  0.25103114]][ 0.0079424  -0.01199635 -0.03888014 -0.01426011]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[ 0.0079424  -0.01199635 -0.03888014 -0.01426011]][ 0.00233337 -0.40380771 -0.01876172  0.53611878]\n",
      "\n",
      "[[-0.01611837 -0.3601332   0.03304061  0.59670463]][[-0.0291388  -0.41952597  0.0531605   0.6750819 ]]\n",
      "[[ 0.00233337 -0.40380771 -0.01876172  0.53611878]]\n",
      "tensor([[ 0.0079, -0.0120, -0.0389, -0.0143]])\n",
      "\n",
      "tensor([[-0.0161, -0.3601,  0.0330,  0.5967]])tensor([[ 0.0023, -0.4038, -0.0188,  0.5361]])tensor([[-0.0291, -0.4195,  0.0532,  0.6751]])[ 0.00770247 -0.20653976 -0.03916534  0.2659066 ]\n",
      "\n",
      "\n",
      "\n",
      "[[ 0.00770247 -0.20653976 -0.03916534  0.2659066 ]][-0.00574279 -0.20842704 -0.00803934  0.23758374][-0.0017594   0.01022879 -0.02073427 -0.01126666]\n",
      "\n",
      "\n",
      "tensor([[ 0.0077, -0.2065, -0.0392,  0.2659]])[[-0.00574279 -0.20842704 -0.00803934  0.23758374]]\n",
      "\n",
      "[ 0.00357168 -0.40108148 -0.03384721  0.54598372]\n",
      "tensor([[-0.0057, -0.2084, -0.0080,  0.2376]])[[-0.0017594   0.01022879 -0.02073427 -0.01126666]][[ 0.00357168 -0.40108148 -0.03384721  0.54598372]]\n",
      "\n",
      "\n",
      "[-0.00991133 -0.40343322 -0.00328767  0.52772002]tensor([[ 0.0036, -0.4011, -0.0338,  0.5460]])\n",
      "tensor([[-0.0018,  0.0102, -0.0207, -0.0113]])\n",
      "[0.04619904 0.0050325  0.01915721 0.04723771]\n",
      "[-0.00444995 -0.20550071 -0.02292753  0.24283143]\n",
      "[-0.00155483 -0.18458977 -0.0209596   0.27480292]\n",
      "[[-0.00991133 -0.40343322 -0.00328767  0.52772002]]\n",
      "\n",
      "[[-0.00444995 -0.20550071 -0.02292753  0.24283143]][[-0.00155483 -0.18458977 -0.0209596   0.27480292]]\n",
      "\n",
      "tensor([[-0.0099, -0.4034, -0.0033,  0.5277]])[[0.04619904 0.0050325  0.01915721 0.04723771]]\n",
      "\n",
      "tensor([[-0.0044, -0.2055, -0.0229,  0.2428]])\n",
      "tensor([[-0.0016, -0.1846, -0.0210,  0.2748]])[-0.00855997 -0.40028779 -0.0180709   0.52819515]\n",
      "tensor([[0.0462, 0.0050, 0.0192, 0.0472]])\n",
      "[ 0.00465854 -0.00036626 -0.00118142  0.03117877]\n",
      "[-0.00524662 -0.3794065  -0.01546354  0.56080216]\n",
      "[[-0.00855997 -0.40028779 -0.0180709   0.52819515]]\n",
      "[ 0.04629969 -0.19035883  0.02010197  0.34590282]\n",
      "\n",
      "tensor([[-0.0086, -0.4003, -0.0181,  0.5282]])[[-0.00524662 -0.3794065  -0.01546354  0.56080216]]\n",
      "\n",
      "[[ 0.04629969 -0.19035883  0.02010197  0.34590282]][[ 0.00465854 -0.00036626 -0.00118142  0.03117877]]tensor([[-0.0052, -0.3794, -0.0155,  0.5608]])\n",
      "\n",
      "\n",
      "tensor([[ 0.0463, -0.1904,  0.0201,  0.3459]])[-0.01283475 -0.18407097 -0.0042475   0.2632878 ]tensor([[ 0.0047, -0.0004, -0.0012,  0.0312]])\n",
      "\n",
      "\n",
      "[ 0.04249251 -0.38576088  0.02702002  0.64485624]\n",
      "\n",
      "\n",
      "[[-0.01283475 -0.18407097 -0.0042475   0.2632878 ]]\n",
      "[ 0.00465121 -0.19547125 -0.00055784  0.32348871][ 0.02896124 -0.03543666 -0.02647767  0.004557  ][[ 0.04249251 -0.38576088  0.02702002  0.64485624]]tensor([[-0.0128, -0.1841, -0.0042,  0.2633]])\n",
      "[[ 0.00465121 -0.19547125 -0.00055784  0.32348871]]\n",
      "\n",
      "[[ 0.02896124 -0.03543666 -0.02647767  0.004557  ]][-0.01651617 -0.37913204  0.00101825  0.554628  ]tensor([[ 0.0425, -0.3858,  0.0270,  0.6449]])\n",
      "\n",
      "\n",
      "tensor([[ 0.0047, -0.1955, -0.0006,  0.3235]])\n",
      "[[-0.01651617 -0.37913204  0.00101825  0.554628  ]][ 0.03477729 -0.19102568  0.03991715  0.360803  ]tensor([[ 0.0290, -0.0354, -0.0265,  0.0046]])\n",
      "\n",
      "[ 0.00074179 -0.39058525  0.00591193  0.61599566]\n",
      "\n",
      "[ 0.02825251 -0.23016908 -0.02638653  0.28876972][[ 0.03477729 -0.19102568  0.03991715  0.360803  ]]tensor([[-0.0165, -0.3791,  0.0010,  0.5546]])[-0.00050592  0.02492689 -0.0115935  -0.04726481]\n",
      "\n",
      "\n",
      "\n",
      "[[ 0.00074179 -0.39058525  0.00591193  0.61599566]][[ 0.02825251 -0.23016908 -0.02638653  0.28876972]]\n",
      "tensor([[ 0.0348, -0.1910,  0.0399,  0.3608]])\n",
      "\n",
      "tensor([[ 0.0007, -0.3906,  0.0059,  0.6160]])tensor([[ 0.0283, -0.2302, -0.0264,  0.2888]])\n",
      "[ 0.03095678 -0.38669163  0.04713321  0.66580064][[-0.00050592  0.02492689 -0.0115935  -0.04726481]]\n",
      "[-0.00706992 -0.19554639  0.01823184  0.32518059]\n",
      "\n",
      "[ 0.02364913 -0.42490501 -0.02061113  0.57301519]\n",
      "\n",
      "[[-0.00706992 -0.19554639  0.01823184  0.32518059]][[ 0.03095678 -0.38669163  0.04713321  0.66580064]][[ 0.02364913 -0.42490501 -0.02061113  0.57301519]]\n",
      "tensor([[-0.0005,  0.0249, -0.0116, -0.0473]])\n",
      "\n",
      "\n",
      "tensor([[-0.0071, -0.1955,  0.0182,  0.3252]])tensor([[ 0.0236, -0.4249, -0.0206,  0.5730]])\n",
      "tensor([[ 0.0310, -0.3867,  0.0471,  0.6658]])\n",
      "[-7.38169617e-06 -1.70026914e-01 -1.25387946e-02  2.41737836e-01][-0.01098084 -0.39092312  0.02473545  0.62355684][ 0.03796539 -0.0048151  -0.04570226  0.04308587][ 0.01515103 -0.22950022 -0.00915083  0.27391103]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[-0.01098084 -0.39092312  0.02473545  0.62355684]][[ 0.01515103 -0.22950022 -0.00915083  0.27391103]][[-7.38169617e-06 -1.70026914e-01 -1.25387946e-02  2.41737836e-01]]\n",
      "\n",
      "\n",
      "tensor([[-0.0110, -0.3909,  0.0247,  0.6236]])tensor([[ 0.0152, -0.2295, -0.0092,  0.2739]])\n",
      "tensor([[-7.3817e-06, -1.7003e-01, -1.2539e-02,  2.4174e-01]])\n",
      "[[ 0.03796539 -0.0048151  -0.04570226  0.04308587]]\n",
      "[ 0.01056102 -0.42449042 -0.00367261  0.56369377]\n",
      "\n",
      "[-0.00340792 -0.36496753 -0.00770404  0.53043947]\n",
      "tensor([[ 0.0380, -0.0048, -0.0457,  0.0431]])[[ 0.01056102 -0.42449042 -0.00367261  0.56369377]]\n",
      "[[-0.00340792 -0.36496753 -0.00770404  0.53043947]][ 0.00658276  0.01077665 -0.01134228 -0.03871788]\n",
      "\n",
      "[ 0.03786908 -0.19925291 -0.04484055  0.32100627]\n",
      "tensor([[ 0.0106, -0.4245, -0.0037,  0.5637]])\n",
      "tensor([[-0.0034, -0.3650, -0.0077,  0.5304]])\n",
      "\n",
      "[[ 0.03786908 -0.19925291 -0.04484055  0.32100627]][-0.01070727 -0.16973806  0.00290475  0.23533899]\n",
      "\n",
      "[[ 0.00658276  0.01077665 -0.01134228 -0.03871788]]\n",
      "tensor([[ 0.0379, -0.1993, -0.0448,  0.3210]])[[-0.01070727 -0.16973806  0.00290475  0.23533899]]\n",
      "\n",
      "tensor([[ 0.0066,  0.0108, -0.0113, -0.0387]])[ 0.03388403 -0.39370856 -0.03842042  0.59921785]\n",
      "tensor([[-0.0107, -0.1697,  0.0029,  0.2353]])\n",
      "[ 0.00679829 -0.18418083 -0.01211663  0.25036498]\n",
      "\n",
      "[-0.01410203 -0.36490139  0.00761153  0.52893674][[ 0.03388403 -0.39370856 -0.03842042  0.59921785]]\n",
      "\n",
      "[[ 0.00679829 -0.18418083 -0.01211663  0.25036498]][ 0.03103311  0.04151489 -0.03068578  0.01592475]\n",
      "[[-0.01410203 -0.36490139  0.00761153  0.52893674]]\n",
      "tensor([[ 0.0339, -0.3937, -0.0384,  0.5992]])\n",
      "tensor([[ 0.0068, -0.1842, -0.0121,  0.2504]])\n",
      "\n",
      "[ 0.02600985 -0.19807072 -0.02643606  0.29468483]tensor([[-0.0141, -0.3649,  0.0076,  0.5289]])[ 0.00311467 -0.37912768 -0.00710933  0.53920158]\n",
      "\n",
      "\n",
      "[[ 0.03103311  0.04151489 -0.03068578  0.01592475]]\n",
      "[[ 0.00311467 -0.37912768 -0.00710933  0.53920158]][[ 0.02600985 -0.19807072 -0.02643606  0.29468483]]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0310,  0.0415, -0.0307,  0.0159]])tensor([[ 0.0031, -0.3791, -0.0071,  0.5392]])\n",
      "tensor([[ 0.0260, -0.1981, -0.0264,  0.2947]])\n",
      "\n",
      "[ 0.0318634  -0.15315385 -0.03036728  0.2987702 ][-0.00446788 -0.18390651  0.0036747   0.2442871 ][ 0.02204844 -0.392806   -0.02054237  0.57891439]\n",
      "\n",
      "\n",
      "[[ 0.0318634  -0.15315385 -0.03036728  0.2987702 ]][[-0.00446788 -0.18390651  0.0036747   0.2442871 ]][[ 0.02204844 -0.392806   -0.02054237  0.57891439]][ 0.02492307 -0.0487669  -0.04054778  0.03129896]\n",
      "\n",
      "\n",
      "\n",
      "tensor([[-0.0045, -0.1839,  0.0037,  0.2443]])tensor([[ 0.0319, -0.1532, -0.0304,  0.2988]])tensor([[ 0.0220, -0.3928, -0.0205,  0.5789]])\n",
      "\n",
      "\n",
      "[-0.00814601 -0.37908075  0.00856044  0.53812685][ 0.02880033 -0.34783007 -0.02439188  0.58172329]\n",
      "[[ 0.02492307 -0.0487669  -0.04054778  0.03129896]]\n",
      "\n",
      "[[-0.00814601 -0.37908075  0.00856044  0.53812685]]\n",
      "[[ 0.02880033 -0.34783007 -0.02439188  0.58172329]]\n",
      "tensor([[ 0.0249, -0.0488, -0.0405,  0.0313]])tensor([[-0.0081, -0.3791,  0.0086,  0.5381]])\n",
      "\n",
      "tensor([[ 0.0288, -0.3478, -0.0244,  0.5817]])[ 0.02394774 -0.24328463 -0.0399218   0.31091794]\n",
      "\n",
      "[ 0.02184373 -0.15237501 -0.01275741  0.2814574 ][-0.00482598  0.04375207 -0.01914831 -0.01685118]\n",
      "\n",
      "[[ 0.02394774 -0.24328463 -0.0399218   0.31091794]][[ 0.02184373 -0.15237501 -0.01275741  0.2814574 ]]\n",
      "\n",
      "tensor([[ 0.0218, -0.1524, -0.0128,  0.2815]])[[-0.00482598  0.04375207 -0.01914831 -0.01685118]]tensor([[ 0.0239, -0.2433, -0.0399,  0.3109]])\n",
      "\n",
      "\n",
      "[ 0.01879623 -0.34731268 -0.00712826  0.57008954][ 0.01908204 -0.43781574 -0.03370345  0.59074822]\n",
      "tensor([[-0.0048,  0.0438, -0.0191, -0.0169]])\n",
      "\n",
      "[[ 0.01879623 -0.34731268 -0.00712826  0.57008954]][[ 0.01908204 -0.43781574 -0.03370345  0.59074822]]\n",
      "[-0.00395094 -0.15109011 -0.01948534  0.26972926]\n",
      "\n",
      "[ 0.02140153 -0.02013617  0.02618683 -0.01054762]tensor([[ 0.0191, -0.4378, -0.0337,  0.5907]])\n",
      "tensor([[ 0.0188, -0.3473, -0.0071,  0.5701]])\n",
      "[[-0.00395094 -0.15109011 -0.01948534  0.26972926]]\n",
      "[ 0.01032573 -0.24223852 -0.02188848  0.28764206]\n",
      "\n",
      "[[ 0.02140153 -0.02013617  0.02618683 -0.01054762]]tensor([[-0.0040, -0.1511, -0.0195,  0.2697]])\n",
      "\n",
      "[[ 0.01032573 -0.24223852 -0.02188848  0.28764206]]\n",
      "tensor([[ 0.0214, -0.0201,  0.0262, -0.0105]])[-0.00697274 -0.34592866 -0.01409075  0.55620326]\n",
      "\n",
      "tensor([[ 0.0103, -0.2422, -0.0219,  0.2876]])[ 0.0209988  -0.2156237   0.02597588  0.29028118][[-0.00697274 -0.34592866 -0.01409075  0.55620326]]\n",
      "\n",
      "\n",
      "[[ 0.0209988  -0.2156237   0.02597588  0.29028118]][ 0.00548096 -0.4370416  -0.01613564  0.57334198]tensor([[-0.0070, -0.3459, -0.0141,  0.5562]])\n",
      "\n",
      "\n",
      "tensor([[ 0.0210, -0.2156,  0.0260,  0.2903]])[-0.01389131 -0.15061174 -0.00296669  0.25911443]\n",
      "[[ 0.00548096 -0.4370416  -0.01613564  0.57334198]]\n",
      "[ 0.01668633 -0.41110623  0.0317815   0.59104211]\n",
      "\n",
      "[[-0.01389131 -0.15061174 -0.00296669  0.25911443]]tensor([[ 0.0055, -0.4370, -0.0161,  0.5733]])\n",
      "[[ 0.01668633 -0.41110623  0.0317815   0.59104211]]\n",
      "\n",
      "tensor([[-0.0139, -0.1506, -0.0030,  0.2591]])\n",
      "tensor([[ 0.0167, -0.4111,  0.0318,  0.5910]])[-0.01690355 -0.34569121  0.0022156   0.55086015]\n",
      "\n",
      "[ 0.00846421 -0.21644332  0.04360234  0.30853739]\n",
      "[[-0.01690355 -0.34569121  0.0022156   0.55086015]]\n",
      "[[ 0.00846421 -0.21644332  0.04360234  0.30853739]]tensor([[-0.0169, -0.3457,  0.0022,  0.5509]])\n",
      "\n",
      "tensor([[ 0.0085, -0.2164,  0.0436,  0.3085]])\n",
      "[ 0.00413534 -0.41215854  0.04977309  0.61464623]\n",
      "[[ 0.00413534 -0.41215854  0.04977309  0.61464623]]\n",
      "tensor([[ 0.0041, -0.4122,  0.0498,  0.6146]])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-137-9d0575d65391>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m                    \u001b[0;31m# record episode reward to plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/or/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/or/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"negative maxlength\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bad_message_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/or/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxsize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/or/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gnet = Net(N_S, N_A)        # global network\n",
    "gnet.share_memory()         # share the global parameters in multiprocessing\n",
    "opt = SharedAdam(gnet.parameters(), lr=1e-4, betas=(0.92, 0.999))      # global optimizer\n",
    "global_ep, global_ep_r, res_queue = mp.Value('i', 0), mp.Value('d', 0.), mp.Queue()\n",
    "print(mp.cpu_count())\n",
    "\n",
    "# parallel training\n",
    "workers = [Worker(gnet, opt, global_ep, global_ep_r, res_queue, i) for i in range(mp.cpu_count())]\n",
    "[w.start() for w in workers]\n",
    "res = []                    # record episode reward to plot\n",
    "while True:\n",
    "    r = res_queue.get()\n",
    "    if r is not None:\n",
    "        res.append(r)\n",
    "    else:\n",
    "        break\n",
    "[w.join() for w in workers]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(res)\n",
    "plt.ylabel('Moving average ep reward')\n",
    "plt.xlabel('Step')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "material-pulse",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charming-stocks",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
