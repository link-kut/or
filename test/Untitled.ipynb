{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "foreign-chinese",
   "metadata": {},
   "source": [
    "# GCN practice code\n",
    "\n",
    "- import basic library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "unexpected-worth",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import from_networkx\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from random import randint, expovariate\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinct-adventure",
   "metadata": {},
   "source": [
    "- Generate the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overhead-elements",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nx.gnm_random_graph(n=20, m=100)\n",
    "\n",
    "min_cpu_capacity = 1.0e10\n",
    "max_cpu_capacity = 0.0\n",
    "for node_id in net.nodes:\n",
    "    net.nodes[node_id]['CPU'] = randint(50, 100)\n",
    "    net.nodes[node_id]['LOCATION'] = randint(0, 2)\n",
    "    if net.nodes[node_id]['CPU'] < min_cpu_capacity:\n",
    "        min_cpu_capacity = net.nodes[node_id]['CPU']\n",
    "    if net.nodes[node_id]['CPU'] > max_cpu_capacity:\n",
    "        max_cpu_capacity = net.nodes[node_id]['CPU']\n",
    "        \n",
    "min_bandwidth_capacity = 1.0e10\n",
    "max_bandwidth_capacity = 0.0\n",
    "for edge_id in net.edges:\n",
    "    net.edges[edge_id]['bandwidth'] = randint(50, 100)\n",
    "    if net.edges[edge_id]['bandwidth'] < min_bandwidth_capacity:\n",
    "        min_bandwidth_capacity = net.edges[edge_id]['bandwidth']\n",
    "    if net.edges[edge_id]['bandwidth'] > max_bandwidth_capacity:\n",
    "        max_bandwidth_capacity = net.edges[edge_id]['bandwidth']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simple-morris",
   "metadata": {},
   "source": [
    "- Using 'from_networkx'\n",
    "    - transfer the torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "prerequisite-ireland",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = from_networkx(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "stopped-clock",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(CPU=[20], LOCATION=[20], bandwidth=[200], edge_index=[2, 200])\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "nominated-bennett",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.edge_index.shape: torch.Size([2, 200])\n",
      "data.CPU.shape: torch.Size([20])\n",
      "data.bandwidth.shape: torch.Size([200])\n",
      "-------------------\n",
      "data.edge_index: tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,  1,  2,\n",
      "          2,  2,  2,  2,  2,  2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  3,  3,  4,\n",
      "          4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  5,  5,  5,  5,  5,  5,  5,  5,\n",
      "          5,  5,  5,  5,  5,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  7,  7,  7,\n",
      "          7,  7,  7,  7,  7,  8,  8,  8,  8,  8,  8,  8,  8,  8,  9,  9,  9,  9,\n",
      "          9,  9,  9,  9,  9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "         11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
      "         12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14,\n",
      "         14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16,\n",
      "         17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18,\n",
      "         18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19,\n",
      "         19, 19],\n",
      "        [18,  5,  3, 13, 12,  9,  2, 17,  8, 19, 12,  5,  4, 17, 14, 18, 10,  0,\n",
      "          6,  5, 18, 17,  8,  9, 12, 15,  0, 12, 19,  7,  6, 11, 18,  4,  5,  1,\n",
      "          3, 14,  9,  5, 18, 12,  6, 10, 11, 19,  0,  1,  2,  3,  4, 13, 12, 16,\n",
      "          8, 10, 14,  6,  9,  2,  3,  4,  5, 10, 15,  7, 19, 11, 12,  3,  6, 15,\n",
      "         19, 14, 13, 16, 10,  0,  2,  5, 17, 19, 12, 10, 11,  9,  0,  2,  4,  5,\n",
      "          8, 12, 19, 11, 16,  1,  4,  5,  6,  7,  8, 13, 16, 15, 18, 17, 19, 12,\n",
      "          3,  4,  6,  8,  9, 17, 19, 15,  0,  1,  2,  3,  4,  5,  6,  8,  9, 10,\n",
      "         15, 17, 19, 14, 16,  0,  5,  7, 10, 19, 18,  1,  4,  5,  7, 12, 16, 19,\n",
      "         18,  2,  6,  7, 10, 11, 12, 17, 18, 19,  5,  7,  9, 10, 12, 14, 19, 17,\n",
      "          0,  1,  2,  8, 10, 11, 12, 15, 16, 19, 18,  0,  1,  2,  3,  4, 10, 13,\n",
      "         14, 15, 17, 19,  1,  3,  4,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "         17, 18]])\n",
      "data.CPU: tensor([100,  51,  70,  59,  59,  75,  62,  58,  79,  68,  77,  59,  57,  84,\n",
      "         85,  88,  99,  69,  99,  90])\n",
      "data.bandwidth: tensor([ 66,  73,  84,  60,  58,  78,  92,  78,  82,  87,  88,  72,  66,  62,\n",
      "         63,  81,  70,  92,  57,  70,  57,  53,  81,  60,  71,  97,  84,  96,\n",
      "         56,  91,  83,  89,  79,  86,  81,  66,  86,  61,  74,  84,  84,  63,\n",
      "         70,  53,  65,  54,  73,  72,  70,  81,  84,  98,  77,  99,  98,  78,\n",
      "         88,  59,  73,  57,  83,  70,  59,  89,  58,  60,  55,  91,  92,  91,\n",
      "         60,  93,  80,  55,  89,  50,  91,  82,  81,  98,  98,  97,  53,  57,\n",
      "         59,  54,  78,  60,  74,  73,  54, 100,  62,  89,  68,  70,  53,  78,\n",
      "         89,  91,  57,  57,  96,  81,  68,  95,  75,  52,  89,  65,  91,  59,\n",
      "         89,  80,  57,  88,  58,  88,  71,  96,  63,  77,  92,  53, 100,  52,\n",
      "         84,  89,  61,  85,  97,  60,  98,  89,  57,  55,  79,  63,  61,  88,\n",
      "         55,  85,  54,  61,  97,  97,  58,  93,  81,  88,  84,  68,  87,  65,\n",
      "         99,  50,  68,  96,  97,  54,  87,  76,  78,  62,  53,  98,  95,  80,\n",
      "         89,  68,  76,  77,  74,  66,  81,  57,  79,  84,  68,  79,  97,  87,\n",
      "         74,  95,  87,  56,  54,  55,  80,  97,  62,  75,  57,  61,  55,  61,\n",
      "         65,  87,  77,  95])\n"
     ]
    }
   ],
   "source": [
    "print(f'data.edge_index.shape: {data.edge_index.shape}')\n",
    "print(f'data.CPU.shape: {data.CPU.shape}')\n",
    "print(f'data.bandwidth.shape: {data.bandwidth.shape}')\n",
    "print(\"-------------------\")\n",
    "print(f'data.edge_index: {data.edge_index}')\n",
    "print(f'data.CPU: {data.CPU}')\n",
    "print(f'data.bandwidth: {data.bandwidth}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "quantitative-vehicle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: KarateClub():\n",
      "======================\n",
      "Number of graphs: 1\n",
      "Number of features: 34\n",
      "Number of classes: 3\n",
      "Data(edge_index=[2, 156], train_mask=[34], x=[34, 34], y=[34])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import KarateClub\n",
    "\n",
    "dataset = KarateClub()\n",
    "print(f'Dataset: {dataset}:')\n",
    "print('======================')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')\n",
    "\n",
    "data = dataset[0]  # Get the first graph object.\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optical-drain",
   "metadata": {},
   "source": [
    "### Graph Convolution Network\n",
    "- Generate the GCN class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "headed-hurricane",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (conv1): GCNConv(0, 4)\n",
      "  (conv2): GCNConv(4, 4)\n",
      "  (conv3): GCNConv(4, 2)\n",
      "  (classifier): Linear(in_features=2, out_features=20, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import Linear\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = GCNConv(in_channels=data.num_features, out_channels=4)\n",
    "        self.conv2 = GCNConv(in_channels=4, out_channels=4)\n",
    "        self.conv3 = GCNConv(in_channels=4, out_channels=2)\n",
    "        self.classifier = Linear(2, 20)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        h = self.conv1(x, edge_index)\n",
    "        h = h.tanh()\n",
    "        h = self.conv2(h, edge_index)\n",
    "        h = h.tanh()\n",
    "        h = self.conv3(h, edge_index)\n",
    "        h = h.tanh()  # Final GNN embedding space.\n",
    "        \n",
    "        # Apply a final (linear) classifier.\n",
    "        out = self.classifier(h)\n",
    "\n",
    "        return out, h\n",
    "\n",
    "model = GCN()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moral-taiwan",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
